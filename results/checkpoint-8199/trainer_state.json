{
  "best_global_step": 8199,
  "best_metric": 1.2700310945510864,
  "best_model_checkpoint": "./results/checkpoint-8199",
  "epoch": 3.0,
  "eval_steps": 500,
  "global_step": 8199,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.018294914013904134,
      "grad_norm": 3.2521326541900635,
      "learning_rate": 4.9000000000000005e-06,
      "loss": 2.2651,
      "step": 50
    },
    {
      "epoch": 0.03658982802780827,
      "grad_norm": 2.981189727783203,
      "learning_rate": 9.900000000000002e-06,
      "loss": 2.0777,
      "step": 100
    },
    {
      "epoch": 0.054884742041712405,
      "grad_norm": 2.9226150512695312,
      "learning_rate": 1.49e-05,
      "loss": 1.9632,
      "step": 150
    },
    {
      "epoch": 0.07317965605561653,
      "grad_norm": 4.199420928955078,
      "learning_rate": 1.9900000000000003e-05,
      "loss": 1.9342,
      "step": 200
    },
    {
      "epoch": 0.09147457006952067,
      "grad_norm": 2.8659472465515137,
      "learning_rate": 2.4900000000000002e-05,
      "loss": 1.9042,
      "step": 250
    },
    {
      "epoch": 0.10976948408342481,
      "grad_norm": 3.1276392936706543,
      "learning_rate": 2.9900000000000002e-05,
      "loss": 1.8743,
      "step": 300
    },
    {
      "epoch": 0.12806439809732895,
      "grad_norm": 4.388223171234131,
      "learning_rate": 3.49e-05,
      "loss": 1.7266,
      "step": 350
    },
    {
      "epoch": 0.14635931211123307,
      "grad_norm": 3.7878572940826416,
      "learning_rate": 3.99e-05,
      "loss": 1.7985,
      "step": 400
    },
    {
      "epoch": 0.16465422612513722,
      "grad_norm": 4.925199031829834,
      "learning_rate": 4.49e-05,
      "loss": 1.7541,
      "step": 450
    },
    {
      "epoch": 0.18294914013904134,
      "grad_norm": 3.410421133041382,
      "learning_rate": 4.99e-05,
      "loss": 1.815,
      "step": 500
    },
    {
      "epoch": 0.20124405415294547,
      "grad_norm": 3.661022901535034,
      "learning_rate": 4.96817768541369e-05,
      "loss": 1.7725,
      "step": 550
    },
    {
      "epoch": 0.21953896816684962,
      "grad_norm": 4.012839317321777,
      "learning_rate": 4.935705935835823e-05,
      "loss": 1.785,
      "step": 600
    },
    {
      "epoch": 0.23783388218075374,
      "grad_norm": 4.304869174957275,
      "learning_rate": 4.903234186257955e-05,
      "loss": 1.7429,
      "step": 650
    },
    {
      "epoch": 0.2561287961946579,
      "grad_norm": 3.617032051086426,
      "learning_rate": 4.870762436680089e-05,
      "loss": 1.7645,
      "step": 700
    },
    {
      "epoch": 0.27442371020856204,
      "grad_norm": 3.871690273284912,
      "learning_rate": 4.838290687102222e-05,
      "loss": 1.7066,
      "step": 750
    },
    {
      "epoch": 0.29271862422246614,
      "grad_norm": 5.437191009521484,
      "learning_rate": 4.805818937524354e-05,
      "loss": 1.7179,
      "step": 800
    },
    {
      "epoch": 0.3110135382363703,
      "grad_norm": 3.758509397506714,
      "learning_rate": 4.773347187946487e-05,
      "loss": 1.7389,
      "step": 850
    },
    {
      "epoch": 0.32930845225027444,
      "grad_norm": 3.560115098953247,
      "learning_rate": 4.740875438368619e-05,
      "loss": 1.7254,
      "step": 900
    },
    {
      "epoch": 0.34760336626417854,
      "grad_norm": 3.7343385219573975,
      "learning_rate": 4.708403688790752e-05,
      "loss": 1.7526,
      "step": 950
    },
    {
      "epoch": 0.3658982802780827,
      "grad_norm": 3.624098062515259,
      "learning_rate": 4.6759319392128844e-05,
      "loss": 1.7104,
      "step": 1000
    },
    {
      "epoch": 0.38419319429198684,
      "grad_norm": 3.2152633666992188,
      "learning_rate": 4.643460189635018e-05,
      "loss": 1.6564,
      "step": 1050
    },
    {
      "epoch": 0.40248810830589093,
      "grad_norm": 4.167304515838623,
      "learning_rate": 4.610988440057151e-05,
      "loss": 1.7022,
      "step": 1100
    },
    {
      "epoch": 0.4207830223197951,
      "grad_norm": 5.917141437530518,
      "learning_rate": 4.578516690479283e-05,
      "loss": 1.676,
      "step": 1150
    },
    {
      "epoch": 0.43907793633369924,
      "grad_norm": 4.765353202819824,
      "learning_rate": 4.546044940901416e-05,
      "loss": 1.6519,
      "step": 1200
    },
    {
      "epoch": 0.4573728503476034,
      "grad_norm": 3.0917251110076904,
      "learning_rate": 4.5135731913235484e-05,
      "loss": 1.6421,
      "step": 1250
    },
    {
      "epoch": 0.4756677643615075,
      "grad_norm": 3.6252732276916504,
      "learning_rate": 4.4811014417456814e-05,
      "loss": 1.7119,
      "step": 1300
    },
    {
      "epoch": 0.49396267837541163,
      "grad_norm": 4.548698425292969,
      "learning_rate": 4.448629692167814e-05,
      "loss": 1.653,
      "step": 1350
    },
    {
      "epoch": 0.5122575923893158,
      "grad_norm": 4.444965362548828,
      "learning_rate": 4.4161579425899465e-05,
      "loss": 1.6416,
      "step": 1400
    },
    {
      "epoch": 0.5305525064032199,
      "grad_norm": 4.485790729522705,
      "learning_rate": 4.38368619301208e-05,
      "loss": 1.6584,
      "step": 1450
    },
    {
      "epoch": 0.5488474204171241,
      "grad_norm": 4.275991916656494,
      "learning_rate": 4.3512144434342124e-05,
      "loss": 1.669,
      "step": 1500
    },
    {
      "epoch": 0.5671423344310281,
      "grad_norm": 3.7026264667510986,
      "learning_rate": 4.318742693856345e-05,
      "loss": 1.6699,
      "step": 1550
    },
    {
      "epoch": 0.5854372484449323,
      "grad_norm": 6.692944526672363,
      "learning_rate": 4.286270944278478e-05,
      "loss": 1.6346,
      "step": 1600
    },
    {
      "epoch": 0.6037321624588364,
      "grad_norm": 3.5273561477661133,
      "learning_rate": 4.2537991947006105e-05,
      "loss": 1.6495,
      "step": 1650
    },
    {
      "epoch": 0.6220270764727406,
      "grad_norm": 5.237008094787598,
      "learning_rate": 4.2213274451227434e-05,
      "loss": 1.5688,
      "step": 1700
    },
    {
      "epoch": 0.6403219904866447,
      "grad_norm": 5.399596691131592,
      "learning_rate": 4.188855695544876e-05,
      "loss": 1.5651,
      "step": 1750
    },
    {
      "epoch": 0.6586169045005489,
      "grad_norm": 3.3824918270111084,
      "learning_rate": 4.156383945967009e-05,
      "loss": 1.629,
      "step": 1800
    },
    {
      "epoch": 0.676911818514453,
      "grad_norm": 4.285636901855469,
      "learning_rate": 4.1239121963891416e-05,
      "loss": 1.6499,
      "step": 1850
    },
    {
      "epoch": 0.6952067325283571,
      "grad_norm": 3.7256548404693604,
      "learning_rate": 4.0914404468112745e-05,
      "loss": 1.6491,
      "step": 1900
    },
    {
      "epoch": 0.7135016465422612,
      "grad_norm": 4.285409450531006,
      "learning_rate": 4.0589686972334074e-05,
      "loss": 1.5134,
      "step": 1950
    },
    {
      "epoch": 0.7317965605561654,
      "grad_norm": 3.6610076427459717,
      "learning_rate": 4.02649694765554e-05,
      "loss": 1.5841,
      "step": 2000
    },
    {
      "epoch": 0.7500914745700695,
      "grad_norm": 4.5414252281188965,
      "learning_rate": 3.9940251980776726e-05,
      "loss": 1.5717,
      "step": 2050
    },
    {
      "epoch": 0.7683863885839737,
      "grad_norm": 3.855231523513794,
      "learning_rate": 3.961553448499805e-05,
      "loss": 1.5975,
      "step": 2100
    },
    {
      "epoch": 0.7866813025978778,
      "grad_norm": 3.970301389694214,
      "learning_rate": 3.929081698921938e-05,
      "loss": 1.5977,
      "step": 2150
    },
    {
      "epoch": 0.8049762166117819,
      "grad_norm": 3.383936882019043,
      "learning_rate": 3.8966099493440714e-05,
      "loss": 1.6294,
      "step": 2200
    },
    {
      "epoch": 0.823271130625686,
      "grad_norm": 3.492981195449829,
      "learning_rate": 3.8641381997662036e-05,
      "loss": 1.5933,
      "step": 2250
    },
    {
      "epoch": 0.8415660446395902,
      "grad_norm": 4.699928283691406,
      "learning_rate": 3.8316664501883366e-05,
      "loss": 1.5246,
      "step": 2300
    },
    {
      "epoch": 0.8598609586534943,
      "grad_norm": 4.026318073272705,
      "learning_rate": 3.799194700610469e-05,
      "loss": 1.6831,
      "step": 2350
    },
    {
      "epoch": 0.8781558726673985,
      "grad_norm": 4.255614280700684,
      "learning_rate": 3.766722951032602e-05,
      "loss": 1.5997,
      "step": 2400
    },
    {
      "epoch": 0.8964507866813026,
      "grad_norm": 4.855715751647949,
      "learning_rate": 3.734251201454734e-05,
      "loss": 1.6188,
      "step": 2450
    },
    {
      "epoch": 0.9147457006952068,
      "grad_norm": 6.434935092926025,
      "learning_rate": 3.701779451876867e-05,
      "loss": 1.5491,
      "step": 2500
    },
    {
      "epoch": 0.9330406147091108,
      "grad_norm": 4.883231163024902,
      "learning_rate": 3.6693077022990005e-05,
      "loss": 1.5512,
      "step": 2550
    },
    {
      "epoch": 0.951335528723015,
      "grad_norm": 3.9118618965148926,
      "learning_rate": 3.636835952721133e-05,
      "loss": 1.6619,
      "step": 2600
    },
    {
      "epoch": 0.9696304427369191,
      "grad_norm": 5.228323459625244,
      "learning_rate": 3.604364203143266e-05,
      "loss": 1.5657,
      "step": 2650
    },
    {
      "epoch": 0.9879253567508233,
      "grad_norm": 6.389960765838623,
      "learning_rate": 3.571892453565398e-05,
      "loss": 1.5533,
      "step": 2700
    },
    {
      "epoch": 1.0,
      "eval_accuracy": 0.4280716196748302,
      "eval_f1": 0.39920357611250257,
      "eval_loss": 1.5722179412841797,
      "eval_precision": 0.44052037922375575,
      "eval_recall": 0.4280716196748302,
      "eval_runtime": 13.5484,
      "eval_samples_per_second": 358.64,
      "eval_steps_per_second": 22.438,
      "step": 2733
    },
    {
      "epoch": 1.0062202707647274,
      "grad_norm": 8.148622512817383,
      "learning_rate": 3.539420703987531e-05,
      "loss": 1.5743,
      "step": 2750
    },
    {
      "epoch": 1.0245151847786316,
      "grad_norm": 7.230289459228516,
      "learning_rate": 3.506948954409664e-05,
      "loss": 1.492,
      "step": 2800
    },
    {
      "epoch": 1.0428100987925357,
      "grad_norm": 5.19746208190918,
      "learning_rate": 3.474477204831796e-05,
      "loss": 1.4589,
      "step": 2850
    },
    {
      "epoch": 1.0611050128064399,
      "grad_norm": 7.9762701988220215,
      "learning_rate": 3.44200545525393e-05,
      "loss": 1.4745,
      "step": 2900
    },
    {
      "epoch": 1.079399926820344,
      "grad_norm": 4.729109287261963,
      "learning_rate": 3.409533705676062e-05,
      "loss": 1.4636,
      "step": 2950
    },
    {
      "epoch": 1.0976948408342482,
      "grad_norm": 6.480077266693115,
      "learning_rate": 3.377061956098195e-05,
      "loss": 1.4276,
      "step": 3000
    },
    {
      "epoch": 1.1159897548481523,
      "grad_norm": 4.562735557556152,
      "learning_rate": 3.344590206520328e-05,
      "loss": 1.5047,
      "step": 3050
    },
    {
      "epoch": 1.1342846688620563,
      "grad_norm": 9.734992980957031,
      "learning_rate": 3.31211845694246e-05,
      "loss": 1.4865,
      "step": 3100
    },
    {
      "epoch": 1.1525795828759604,
      "grad_norm": 6.613262176513672,
      "learning_rate": 3.279646707364593e-05,
      "loss": 1.4453,
      "step": 3150
    },
    {
      "epoch": 1.1708744968898646,
      "grad_norm": 5.005685329437256,
      "learning_rate": 3.247174957786725e-05,
      "loss": 1.447,
      "step": 3200
    },
    {
      "epoch": 1.1891694109037687,
      "grad_norm": 6.7127156257629395,
      "learning_rate": 3.214703208208858e-05,
      "loss": 1.4758,
      "step": 3250
    },
    {
      "epoch": 1.2074643249176729,
      "grad_norm": 7.365718841552734,
      "learning_rate": 3.182231458630991e-05,
      "loss": 1.4895,
      "step": 3300
    },
    {
      "epoch": 1.225759238931577,
      "grad_norm": 8.684340476989746,
      "learning_rate": 3.149759709053124e-05,
      "loss": 1.43,
      "step": 3350
    },
    {
      "epoch": 1.2440541529454812,
      "grad_norm": 7.524971961975098,
      "learning_rate": 3.117287959475257e-05,
      "loss": 1.5269,
      "step": 3400
    },
    {
      "epoch": 1.2623490669593853,
      "grad_norm": 4.788549900054932,
      "learning_rate": 3.084816209897389e-05,
      "loss": 1.4242,
      "step": 3450
    },
    {
      "epoch": 1.2806439809732895,
      "grad_norm": 4.284295082092285,
      "learning_rate": 3.052344460319522e-05,
      "loss": 1.4601,
      "step": 3500
    },
    {
      "epoch": 1.2989388949871936,
      "grad_norm": 8.241738319396973,
      "learning_rate": 3.0198727107416547e-05,
      "loss": 1.4449,
      "step": 3550
    },
    {
      "epoch": 1.3172338090010978,
      "grad_norm": 6.199195384979248,
      "learning_rate": 2.9874009611637877e-05,
      "loss": 1.4119,
      "step": 3600
    },
    {
      "epoch": 1.3355287230150017,
      "grad_norm": 7.261866092681885,
      "learning_rate": 2.9549292115859206e-05,
      "loss": 1.4653,
      "step": 3650
    },
    {
      "epoch": 1.3538236370289058,
      "grad_norm": 7.943980693817139,
      "learning_rate": 2.9224574620080532e-05,
      "loss": 1.4675,
      "step": 3700
    },
    {
      "epoch": 1.37211855104281,
      "grad_norm": 6.503689289093018,
      "learning_rate": 2.889985712430186e-05,
      "loss": 1.4015,
      "step": 3750
    },
    {
      "epoch": 1.3904134650567141,
      "grad_norm": 7.585979461669922,
      "learning_rate": 2.8575139628523184e-05,
      "loss": 1.4482,
      "step": 3800
    },
    {
      "epoch": 1.4087083790706183,
      "grad_norm": 7.311662673950195,
      "learning_rate": 2.8250422132744513e-05,
      "loss": 1.4361,
      "step": 3850
    },
    {
      "epoch": 1.4270032930845225,
      "grad_norm": 8.808389663696289,
      "learning_rate": 2.7925704636965842e-05,
      "loss": 1.4427,
      "step": 3900
    },
    {
      "epoch": 1.4452982070984266,
      "grad_norm": 6.6724138259887695,
      "learning_rate": 2.760098714118717e-05,
      "loss": 1.421,
      "step": 3950
    },
    {
      "epoch": 1.4635931211123308,
      "grad_norm": 7.4433112144470215,
      "learning_rate": 2.7276269645408498e-05,
      "loss": 1.428,
      "step": 4000
    },
    {
      "epoch": 1.481888035126235,
      "grad_norm": 6.283499717712402,
      "learning_rate": 2.695155214962982e-05,
      "loss": 1.3968,
      "step": 4050
    },
    {
      "epoch": 1.500182949140139,
      "grad_norm": 7.91911506652832,
      "learning_rate": 2.6626834653851153e-05,
      "loss": 1.4221,
      "step": 4100
    },
    {
      "epoch": 1.5184778631540432,
      "grad_norm": 8.28179931640625,
      "learning_rate": 2.6302117158072475e-05,
      "loss": 1.3483,
      "step": 4150
    },
    {
      "epoch": 1.5367727771679474,
      "grad_norm": 7.213799476623535,
      "learning_rate": 2.5977399662293805e-05,
      "loss": 1.3745,
      "step": 4200
    },
    {
      "epoch": 1.5550676911818515,
      "grad_norm": 7.921483993530273,
      "learning_rate": 2.5652682166515134e-05,
      "loss": 1.41,
      "step": 4250
    },
    {
      "epoch": 1.5733626051957557,
      "grad_norm": 7.0079569816589355,
      "learning_rate": 2.532796467073646e-05,
      "loss": 1.353,
      "step": 4300
    },
    {
      "epoch": 1.5916575192096598,
      "grad_norm": 8.723793983459473,
      "learning_rate": 2.500324717495779e-05,
      "loss": 1.3697,
      "step": 4350
    },
    {
      "epoch": 1.609952433223564,
      "grad_norm": 7.345345497131348,
      "learning_rate": 2.4678529679179115e-05,
      "loss": 1.395,
      "step": 4400
    },
    {
      "epoch": 1.6282473472374681,
      "grad_norm": 10.522229194641113,
      "learning_rate": 2.4353812183400444e-05,
      "loss": 1.4014,
      "step": 4450
    },
    {
      "epoch": 1.6465422612513723,
      "grad_norm": 6.336649417877197,
      "learning_rate": 2.402909468762177e-05,
      "loss": 1.4225,
      "step": 4500
    },
    {
      "epoch": 1.6648371752652764,
      "grad_norm": 8.221672058105469,
      "learning_rate": 2.3704377191843096e-05,
      "loss": 1.3634,
      "step": 4550
    },
    {
      "epoch": 1.6831320892791803,
      "grad_norm": 9.385917663574219,
      "learning_rate": 2.3379659696064422e-05,
      "loss": 1.3631,
      "step": 4600
    },
    {
      "epoch": 1.7014270032930845,
      "grad_norm": 7.8666911125183105,
      "learning_rate": 2.3054942200285755e-05,
      "loss": 1.3594,
      "step": 4650
    },
    {
      "epoch": 1.7197219173069886,
      "grad_norm": 9.682639122009277,
      "learning_rate": 2.273022470450708e-05,
      "loss": 1.4075,
      "step": 4700
    },
    {
      "epoch": 1.7380168313208928,
      "grad_norm": 8.985036849975586,
      "learning_rate": 2.2405507208728407e-05,
      "loss": 1.3888,
      "step": 4750
    },
    {
      "epoch": 1.756311745334797,
      "grad_norm": 9.118685722351074,
      "learning_rate": 2.2080789712949733e-05,
      "loss": 1.3942,
      "step": 4800
    },
    {
      "epoch": 1.774606659348701,
      "grad_norm": 8.121454238891602,
      "learning_rate": 2.1756072217171062e-05,
      "loss": 1.343,
      "step": 4850
    },
    {
      "epoch": 1.7929015733626052,
      "grad_norm": 10.409296035766602,
      "learning_rate": 2.143135472139239e-05,
      "loss": 1.3261,
      "step": 4900
    },
    {
      "epoch": 1.8111964873765092,
      "grad_norm": 6.810938835144043,
      "learning_rate": 2.1106637225613717e-05,
      "loss": 1.3801,
      "step": 4950
    },
    {
      "epoch": 1.8294914013904133,
      "grad_norm": 9.450498580932617,
      "learning_rate": 2.0781919729835046e-05,
      "loss": 1.4001,
      "step": 5000
    },
    {
      "epoch": 1.8477863154043175,
      "grad_norm": 8.710882186889648,
      "learning_rate": 2.0457202234056372e-05,
      "loss": 1.281,
      "step": 5050
    },
    {
      "epoch": 1.8660812294182216,
      "grad_norm": 9.51650619506836,
      "learning_rate": 2.01324847382777e-05,
      "loss": 1.3548,
      "step": 5100
    },
    {
      "epoch": 1.8843761434321258,
      "grad_norm": 9.485401153564453,
      "learning_rate": 1.9807767242499024e-05,
      "loss": 1.3829,
      "step": 5150
    },
    {
      "epoch": 1.90267105744603,
      "grad_norm": 8.025142669677734,
      "learning_rate": 1.9483049746720357e-05,
      "loss": 1.3478,
      "step": 5200
    },
    {
      "epoch": 1.920965971459934,
      "grad_norm": 7.297796726226807,
      "learning_rate": 1.9158332250941683e-05,
      "loss": 1.3711,
      "step": 5250
    },
    {
      "epoch": 1.9392608854738382,
      "grad_norm": 6.171220302581787,
      "learning_rate": 1.883361475516301e-05,
      "loss": 1.2825,
      "step": 5300
    },
    {
      "epoch": 1.9575557994877424,
      "grad_norm": 7.500222206115723,
      "learning_rate": 1.8508897259384335e-05,
      "loss": 1.321,
      "step": 5350
    },
    {
      "epoch": 1.9758507135016465,
      "grad_norm": 8.920764923095703,
      "learning_rate": 1.8184179763605664e-05,
      "loss": 1.3004,
      "step": 5400
    },
    {
      "epoch": 1.9941456275155507,
      "grad_norm": 11.342483520507812,
      "learning_rate": 1.785946226782699e-05,
      "loss": 1.3194,
      "step": 5450
    },
    {
      "epoch": 2.0,
      "eval_accuracy": 0.5217122864786993,
      "eval_f1": 0.5088934792669229,
      "eval_loss": 1.359740138053894,
      "eval_precision": 0.529487724576309,
      "eval_recall": 0.5217122864786993,
      "eval_runtime": 13.6211,
      "eval_samples_per_second": 356.727,
      "eval_steps_per_second": 22.318,
      "step": 5466
    },
    {
      "epoch": 2.012440541529455,
      "grad_norm": 10.512215614318848,
      "learning_rate": 1.753474477204832e-05,
      "loss": 1.2015,
      "step": 5500
    },
    {
      "epoch": 2.030735455543359,
      "grad_norm": 11.725375175476074,
      "learning_rate": 1.721002727626965e-05,
      "loss": 1.0481,
      "step": 5550
    },
    {
      "epoch": 2.049030369557263,
      "grad_norm": 9.914381980895996,
      "learning_rate": 1.6885309780490974e-05,
      "loss": 1.1216,
      "step": 5600
    },
    {
      "epoch": 2.0673252835711673,
      "grad_norm": 7.729986190795898,
      "learning_rate": 1.65605922847123e-05,
      "loss": 1.1287,
      "step": 5650
    },
    {
      "epoch": 2.0856201975850714,
      "grad_norm": 9.78004264831543,
      "learning_rate": 1.6235874788933626e-05,
      "loss": 1.218,
      "step": 5700
    },
    {
      "epoch": 2.1039151115989756,
      "grad_norm": 16.2301082611084,
      "learning_rate": 1.5911157293154956e-05,
      "loss": 1.1549,
      "step": 5750
    },
    {
      "epoch": 2.1222100256128797,
      "grad_norm": 11.550540924072266,
      "learning_rate": 1.5586439797376285e-05,
      "loss": 1.1241,
      "step": 5800
    },
    {
      "epoch": 2.140504939626784,
      "grad_norm": 20.478788375854492,
      "learning_rate": 1.526172230159761e-05,
      "loss": 1.1075,
      "step": 5850
    },
    {
      "epoch": 2.158799853640688,
      "grad_norm": 15.951305389404297,
      "learning_rate": 1.4937004805818938e-05,
      "loss": 1.0885,
      "step": 5900
    },
    {
      "epoch": 2.177094767654592,
      "grad_norm": 9.173147201538086,
      "learning_rate": 1.4612287310040266e-05,
      "loss": 1.0851,
      "step": 5950
    },
    {
      "epoch": 2.1953896816684964,
      "grad_norm": 10.877942085266113,
      "learning_rate": 1.4287569814261592e-05,
      "loss": 1.0544,
      "step": 6000
    },
    {
      "epoch": 2.2136845956824,
      "grad_norm": 13.619072914123535,
      "learning_rate": 1.3962852318482921e-05,
      "loss": 1.045,
      "step": 6050
    },
    {
      "epoch": 2.2319795096963047,
      "grad_norm": 9.094804763793945,
      "learning_rate": 1.3638134822704249e-05,
      "loss": 1.0989,
      "step": 6100
    },
    {
      "epoch": 2.2502744237102084,
      "grad_norm": 12.70372200012207,
      "learning_rate": 1.3313417326925576e-05,
      "loss": 1.0236,
      "step": 6150
    },
    {
      "epoch": 2.2685693377241125,
      "grad_norm": 10.338973045349121,
      "learning_rate": 1.2988699831146902e-05,
      "loss": 1.0732,
      "step": 6200
    },
    {
      "epoch": 2.2868642517380167,
      "grad_norm": 13.878474235534668,
      "learning_rate": 1.266398233536823e-05,
      "loss": 1.1306,
      "step": 6250
    },
    {
      "epoch": 2.305159165751921,
      "grad_norm": 11.795580863952637,
      "learning_rate": 1.2339264839589558e-05,
      "loss": 1.0471,
      "step": 6300
    },
    {
      "epoch": 2.323454079765825,
      "grad_norm": 9.928035736083984,
      "learning_rate": 1.2014547343810885e-05,
      "loss": 1.0425,
      "step": 6350
    },
    {
      "epoch": 2.341748993779729,
      "grad_norm": 12.943466186523438,
      "learning_rate": 1.1689829848032211e-05,
      "loss": 1.0477,
      "step": 6400
    },
    {
      "epoch": 2.3600439077936333,
      "grad_norm": 12.793636322021484,
      "learning_rate": 1.136511235225354e-05,
      "loss": 1.1405,
      "step": 6450
    },
    {
      "epoch": 2.3783388218075374,
      "grad_norm": 13.723755836486816,
      "learning_rate": 1.1040394856474866e-05,
      "loss": 1.0801,
      "step": 6500
    },
    {
      "epoch": 2.3966337358214416,
      "grad_norm": 13.120552062988281,
      "learning_rate": 1.0715677360696196e-05,
      "loss": 1.0193,
      "step": 6550
    },
    {
      "epoch": 2.4149286498353457,
      "grad_norm": 11.503173828125,
      "learning_rate": 1.0390959864917523e-05,
      "loss": 1.0601,
      "step": 6600
    },
    {
      "epoch": 2.43322356384925,
      "grad_norm": 11.422198295593262,
      "learning_rate": 1.006624236913885e-05,
      "loss": 1.1088,
      "step": 6650
    },
    {
      "epoch": 2.451518477863154,
      "grad_norm": 10.177603721618652,
      "learning_rate": 9.741524873360178e-06,
      "loss": 1.0754,
      "step": 6700
    },
    {
      "epoch": 2.469813391877058,
      "grad_norm": 12.408841133117676,
      "learning_rate": 9.416807377581504e-06,
      "loss": 1.0808,
      "step": 6750
    },
    {
      "epoch": 2.4881083058909623,
      "grad_norm": 12.902857780456543,
      "learning_rate": 9.092089881802832e-06,
      "loss": 1.0767,
      "step": 6800
    },
    {
      "epoch": 2.5064032199048665,
      "grad_norm": 15.926226615905762,
      "learning_rate": 8.76737238602416e-06,
      "loss": 1.0555,
      "step": 6850
    },
    {
      "epoch": 2.5246981339187706,
      "grad_norm": 13.568944931030273,
      "learning_rate": 8.442654890245487e-06,
      "loss": 1.0577,
      "step": 6900
    },
    {
      "epoch": 2.5429930479326748,
      "grad_norm": 18.958261489868164,
      "learning_rate": 8.117937394466813e-06,
      "loss": 1.0505,
      "step": 6950
    },
    {
      "epoch": 2.561287961946579,
      "grad_norm": 10.034124374389648,
      "learning_rate": 7.793219898688142e-06,
      "loss": 1.0491,
      "step": 7000
    },
    {
      "epoch": 2.579582875960483,
      "grad_norm": 13.620549201965332,
      "learning_rate": 7.468502402909469e-06,
      "loss": 1.0814,
      "step": 7050
    },
    {
      "epoch": 2.5978777899743872,
      "grad_norm": 13.706735610961914,
      "learning_rate": 7.143784907130796e-06,
      "loss": 0.9749,
      "step": 7100
    },
    {
      "epoch": 2.6161727039882914,
      "grad_norm": 18.030397415161133,
      "learning_rate": 6.819067411352124e-06,
      "loss": 0.9887,
      "step": 7150
    },
    {
      "epoch": 2.6344676180021955,
      "grad_norm": 13.484746932983398,
      "learning_rate": 6.494349915573451e-06,
      "loss": 1.0489,
      "step": 7200
    },
    {
      "epoch": 2.6527625320160997,
      "grad_norm": 15.630356788635254,
      "learning_rate": 6.169632419794779e-06,
      "loss": 0.9937,
      "step": 7250
    },
    {
      "epoch": 2.6710574460300034,
      "grad_norm": 12.258747100830078,
      "learning_rate": 5.8449149240161056e-06,
      "loss": 1.0545,
      "step": 7300
    },
    {
      "epoch": 2.689352360043908,
      "grad_norm": 12.434086799621582,
      "learning_rate": 5.520197428237433e-06,
      "loss": 0.9779,
      "step": 7350
    },
    {
      "epoch": 2.7076472740578117,
      "grad_norm": 10.024978637695312,
      "learning_rate": 5.195479932458762e-06,
      "loss": 1.0595,
      "step": 7400
    },
    {
      "epoch": 2.7259421880717163,
      "grad_norm": 12.882512092590332,
      "learning_rate": 4.870762436680089e-06,
      "loss": 1.0251,
      "step": 7450
    },
    {
      "epoch": 2.74423710208562,
      "grad_norm": 11.656445503234863,
      "learning_rate": 4.546044940901416e-06,
      "loss": 0.9956,
      "step": 7500
    },
    {
      "epoch": 2.7625320160995246,
      "grad_norm": 15.308638572692871,
      "learning_rate": 4.221327445122744e-06,
      "loss": 1.0627,
      "step": 7550
    },
    {
      "epoch": 2.7808269301134283,
      "grad_norm": 11.80106258392334,
      "learning_rate": 3.896609949344071e-06,
      "loss": 1.0499,
      "step": 7600
    },
    {
      "epoch": 2.7991218441273324,
      "grad_norm": 13.462679862976074,
      "learning_rate": 3.571892453565398e-06,
      "loss": 1.0261,
      "step": 7650
    },
    {
      "epoch": 2.8174167581412366,
      "grad_norm": 14.242960929870605,
      "learning_rate": 3.2471749577867256e-06,
      "loss": 1.035,
      "step": 7700
    },
    {
      "epoch": 2.8357116721551408,
      "grad_norm": 18.65184211730957,
      "learning_rate": 2.9224574620080528e-06,
      "loss": 1.034,
      "step": 7750
    },
    {
      "epoch": 2.854006586169045,
      "grad_norm": 11.058837890625,
      "learning_rate": 2.597739966229381e-06,
      "loss": 1.0056,
      "step": 7800
    },
    {
      "epoch": 2.872301500182949,
      "grad_norm": 12.265036582946777,
      "learning_rate": 2.273022470450708e-06,
      "loss": 1.0281,
      "step": 7850
    },
    {
      "epoch": 2.890596414196853,
      "grad_norm": 12.022440910339355,
      "learning_rate": 1.9483049746720356e-06,
      "loss": 1.0429,
      "step": 7900
    },
    {
      "epoch": 2.9088913282107574,
      "grad_norm": 11.535130500793457,
      "learning_rate": 1.6235874788933628e-06,
      "loss": 1.0318,
      "step": 7950
    },
    {
      "epoch": 2.9271862422246615,
      "grad_norm": 18.408145904541016,
      "learning_rate": 1.2988699831146904e-06,
      "loss": 0.9642,
      "step": 8000
    },
    {
      "epoch": 2.9454811562385657,
      "grad_norm": 10.48234748840332,
      "learning_rate": 9.741524873360178e-07,
      "loss": 1.0633,
      "step": 8050
    },
    {
      "epoch": 2.96377607025247,
      "grad_norm": 11.15957260131836,
      "learning_rate": 6.494349915573452e-07,
      "loss": 0.9636,
      "step": 8100
    },
    {
      "epoch": 2.982070984266374,
      "grad_norm": 19.675350189208984,
      "learning_rate": 3.247174957786726e-07,
      "loss": 1.0119,
      "step": 8150
    },
    {
      "epoch": 3.0,
      "eval_accuracy": 0.5758386499279687,
      "eval_f1": 0.5670874864623993,
      "eval_loss": 1.2700310945510864,
      "eval_precision": 0.5803910386506216,
      "eval_recall": 0.5758386499279687,
      "eval_runtime": 14.22,
      "eval_samples_per_second": 341.703,
      "eval_steps_per_second": 21.378,
      "step": 8199
    }
  ],
  "logging_steps": 50,
  "max_steps": 8199,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 3,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 4344821886643200.0,
  "train_batch_size": 16,
  "trial_name": null,
  "trial_params": null
}
