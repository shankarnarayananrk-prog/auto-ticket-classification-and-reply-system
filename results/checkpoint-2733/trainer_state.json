{
  "best_global_step": 2733,
  "best_metric": 1.5722179412841797,
  "best_model_checkpoint": "./results/checkpoint-2733",
  "epoch": 1.0,
  "eval_steps": 500,
  "global_step": 2733,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.018294914013904134,
      "grad_norm": 3.2521326541900635,
      "learning_rate": 4.9000000000000005e-06,
      "loss": 2.2651,
      "step": 50
    },
    {
      "epoch": 0.03658982802780827,
      "grad_norm": 2.981189727783203,
      "learning_rate": 9.900000000000002e-06,
      "loss": 2.0777,
      "step": 100
    },
    {
      "epoch": 0.054884742041712405,
      "grad_norm": 2.9226150512695312,
      "learning_rate": 1.49e-05,
      "loss": 1.9632,
      "step": 150
    },
    {
      "epoch": 0.07317965605561653,
      "grad_norm": 4.199420928955078,
      "learning_rate": 1.9900000000000003e-05,
      "loss": 1.9342,
      "step": 200
    },
    {
      "epoch": 0.09147457006952067,
      "grad_norm": 2.8659472465515137,
      "learning_rate": 2.4900000000000002e-05,
      "loss": 1.9042,
      "step": 250
    },
    {
      "epoch": 0.10976948408342481,
      "grad_norm": 3.1276392936706543,
      "learning_rate": 2.9900000000000002e-05,
      "loss": 1.8743,
      "step": 300
    },
    {
      "epoch": 0.12806439809732895,
      "grad_norm": 4.388223171234131,
      "learning_rate": 3.49e-05,
      "loss": 1.7266,
      "step": 350
    },
    {
      "epoch": 0.14635931211123307,
      "grad_norm": 3.7878572940826416,
      "learning_rate": 3.99e-05,
      "loss": 1.7985,
      "step": 400
    },
    {
      "epoch": 0.16465422612513722,
      "grad_norm": 4.925199031829834,
      "learning_rate": 4.49e-05,
      "loss": 1.7541,
      "step": 450
    },
    {
      "epoch": 0.18294914013904134,
      "grad_norm": 3.410421133041382,
      "learning_rate": 4.99e-05,
      "loss": 1.815,
      "step": 500
    },
    {
      "epoch": 0.20124405415294547,
      "grad_norm": 3.661022901535034,
      "learning_rate": 4.96817768541369e-05,
      "loss": 1.7725,
      "step": 550
    },
    {
      "epoch": 0.21953896816684962,
      "grad_norm": 4.012839317321777,
      "learning_rate": 4.935705935835823e-05,
      "loss": 1.785,
      "step": 600
    },
    {
      "epoch": 0.23783388218075374,
      "grad_norm": 4.304869174957275,
      "learning_rate": 4.903234186257955e-05,
      "loss": 1.7429,
      "step": 650
    },
    {
      "epoch": 0.2561287961946579,
      "grad_norm": 3.617032051086426,
      "learning_rate": 4.870762436680089e-05,
      "loss": 1.7645,
      "step": 700
    },
    {
      "epoch": 0.27442371020856204,
      "grad_norm": 3.871690273284912,
      "learning_rate": 4.838290687102222e-05,
      "loss": 1.7066,
      "step": 750
    },
    {
      "epoch": 0.29271862422246614,
      "grad_norm": 5.437191009521484,
      "learning_rate": 4.805818937524354e-05,
      "loss": 1.7179,
      "step": 800
    },
    {
      "epoch": 0.3110135382363703,
      "grad_norm": 3.758509397506714,
      "learning_rate": 4.773347187946487e-05,
      "loss": 1.7389,
      "step": 850
    },
    {
      "epoch": 0.32930845225027444,
      "grad_norm": 3.560115098953247,
      "learning_rate": 4.740875438368619e-05,
      "loss": 1.7254,
      "step": 900
    },
    {
      "epoch": 0.34760336626417854,
      "grad_norm": 3.7343385219573975,
      "learning_rate": 4.708403688790752e-05,
      "loss": 1.7526,
      "step": 950
    },
    {
      "epoch": 0.3658982802780827,
      "grad_norm": 3.624098062515259,
      "learning_rate": 4.6759319392128844e-05,
      "loss": 1.7104,
      "step": 1000
    },
    {
      "epoch": 0.38419319429198684,
      "grad_norm": 3.2152633666992188,
      "learning_rate": 4.643460189635018e-05,
      "loss": 1.6564,
      "step": 1050
    },
    {
      "epoch": 0.40248810830589093,
      "grad_norm": 4.167304515838623,
      "learning_rate": 4.610988440057151e-05,
      "loss": 1.7022,
      "step": 1100
    },
    {
      "epoch": 0.4207830223197951,
      "grad_norm": 5.917141437530518,
      "learning_rate": 4.578516690479283e-05,
      "loss": 1.676,
      "step": 1150
    },
    {
      "epoch": 0.43907793633369924,
      "grad_norm": 4.765353202819824,
      "learning_rate": 4.546044940901416e-05,
      "loss": 1.6519,
      "step": 1200
    },
    {
      "epoch": 0.4573728503476034,
      "grad_norm": 3.0917251110076904,
      "learning_rate": 4.5135731913235484e-05,
      "loss": 1.6421,
      "step": 1250
    },
    {
      "epoch": 0.4756677643615075,
      "grad_norm": 3.6252732276916504,
      "learning_rate": 4.4811014417456814e-05,
      "loss": 1.7119,
      "step": 1300
    },
    {
      "epoch": 0.49396267837541163,
      "grad_norm": 4.548698425292969,
      "learning_rate": 4.448629692167814e-05,
      "loss": 1.653,
      "step": 1350
    },
    {
      "epoch": 0.5122575923893158,
      "grad_norm": 4.444965362548828,
      "learning_rate": 4.4161579425899465e-05,
      "loss": 1.6416,
      "step": 1400
    },
    {
      "epoch": 0.5305525064032199,
      "grad_norm": 4.485790729522705,
      "learning_rate": 4.38368619301208e-05,
      "loss": 1.6584,
      "step": 1450
    },
    {
      "epoch": 0.5488474204171241,
      "grad_norm": 4.275991916656494,
      "learning_rate": 4.3512144434342124e-05,
      "loss": 1.669,
      "step": 1500
    },
    {
      "epoch": 0.5671423344310281,
      "grad_norm": 3.7026264667510986,
      "learning_rate": 4.318742693856345e-05,
      "loss": 1.6699,
      "step": 1550
    },
    {
      "epoch": 0.5854372484449323,
      "grad_norm": 6.692944526672363,
      "learning_rate": 4.286270944278478e-05,
      "loss": 1.6346,
      "step": 1600
    },
    {
      "epoch": 0.6037321624588364,
      "grad_norm": 3.5273561477661133,
      "learning_rate": 4.2537991947006105e-05,
      "loss": 1.6495,
      "step": 1650
    },
    {
      "epoch": 0.6220270764727406,
      "grad_norm": 5.237008094787598,
      "learning_rate": 4.2213274451227434e-05,
      "loss": 1.5688,
      "step": 1700
    },
    {
      "epoch": 0.6403219904866447,
      "grad_norm": 5.399596691131592,
      "learning_rate": 4.188855695544876e-05,
      "loss": 1.5651,
      "step": 1750
    },
    {
      "epoch": 0.6586169045005489,
      "grad_norm": 3.3824918270111084,
      "learning_rate": 4.156383945967009e-05,
      "loss": 1.629,
      "step": 1800
    },
    {
      "epoch": 0.676911818514453,
      "grad_norm": 4.285636901855469,
      "learning_rate": 4.1239121963891416e-05,
      "loss": 1.6499,
      "step": 1850
    },
    {
      "epoch": 0.6952067325283571,
      "grad_norm": 3.7256548404693604,
      "learning_rate": 4.0914404468112745e-05,
      "loss": 1.6491,
      "step": 1900
    },
    {
      "epoch": 0.7135016465422612,
      "grad_norm": 4.285409450531006,
      "learning_rate": 4.0589686972334074e-05,
      "loss": 1.5134,
      "step": 1950
    },
    {
      "epoch": 0.7317965605561654,
      "grad_norm": 3.6610076427459717,
      "learning_rate": 4.02649694765554e-05,
      "loss": 1.5841,
      "step": 2000
    },
    {
      "epoch": 0.7500914745700695,
      "grad_norm": 4.5414252281188965,
      "learning_rate": 3.9940251980776726e-05,
      "loss": 1.5717,
      "step": 2050
    },
    {
      "epoch": 0.7683863885839737,
      "grad_norm": 3.855231523513794,
      "learning_rate": 3.961553448499805e-05,
      "loss": 1.5975,
      "step": 2100
    },
    {
      "epoch": 0.7866813025978778,
      "grad_norm": 3.970301389694214,
      "learning_rate": 3.929081698921938e-05,
      "loss": 1.5977,
      "step": 2150
    },
    {
      "epoch": 0.8049762166117819,
      "grad_norm": 3.383936882019043,
      "learning_rate": 3.8966099493440714e-05,
      "loss": 1.6294,
      "step": 2200
    },
    {
      "epoch": 0.823271130625686,
      "grad_norm": 3.492981195449829,
      "learning_rate": 3.8641381997662036e-05,
      "loss": 1.5933,
      "step": 2250
    },
    {
      "epoch": 0.8415660446395902,
      "grad_norm": 4.699928283691406,
      "learning_rate": 3.8316664501883366e-05,
      "loss": 1.5246,
      "step": 2300
    },
    {
      "epoch": 0.8598609586534943,
      "grad_norm": 4.026318073272705,
      "learning_rate": 3.799194700610469e-05,
      "loss": 1.6831,
      "step": 2350
    },
    {
      "epoch": 0.8781558726673985,
      "grad_norm": 4.255614280700684,
      "learning_rate": 3.766722951032602e-05,
      "loss": 1.5997,
      "step": 2400
    },
    {
      "epoch": 0.8964507866813026,
      "grad_norm": 4.855715751647949,
      "learning_rate": 3.734251201454734e-05,
      "loss": 1.6188,
      "step": 2450
    },
    {
      "epoch": 0.9147457006952068,
      "grad_norm": 6.434935092926025,
      "learning_rate": 3.701779451876867e-05,
      "loss": 1.5491,
      "step": 2500
    },
    {
      "epoch": 0.9330406147091108,
      "grad_norm": 4.883231163024902,
      "learning_rate": 3.6693077022990005e-05,
      "loss": 1.5512,
      "step": 2550
    },
    {
      "epoch": 0.951335528723015,
      "grad_norm": 3.9118618965148926,
      "learning_rate": 3.636835952721133e-05,
      "loss": 1.6619,
      "step": 2600
    },
    {
      "epoch": 0.9696304427369191,
      "grad_norm": 5.228323459625244,
      "learning_rate": 3.604364203143266e-05,
      "loss": 1.5657,
      "step": 2650
    },
    {
      "epoch": 0.9879253567508233,
      "grad_norm": 6.389960765838623,
      "learning_rate": 3.571892453565398e-05,
      "loss": 1.5533,
      "step": 2700
    },
    {
      "epoch": 1.0,
      "eval_accuracy": 0.4280716196748302,
      "eval_f1": 0.39920357611250257,
      "eval_loss": 1.5722179412841797,
      "eval_precision": 0.44052037922375575,
      "eval_recall": 0.4280716196748302,
      "eval_runtime": 13.5484,
      "eval_samples_per_second": 358.64,
      "eval_steps_per_second": 22.438,
      "step": 2733
    }
  ],
  "logging_steps": 50,
  "max_steps": 8199,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 3,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 1448273962214400.0,
  "train_batch_size": 16,
  "trial_name": null,
  "trial_params": null
}
